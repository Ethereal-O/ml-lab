{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM-gradient decent\n",
    "## 1 实现方法\n",
    "几乎相同于课堂上展示的伪代码，但是使用np与矩阵来进行计算，加速计算速度也减少代码量。\n",
    "最终的损失函数为：\n",
    "$$L(w,w_0|D)=\\left\\{\n",
    "    \\begin{aligned}\n",
    "&\\frac{\\lambda}{2} ||w||^2 &y^{(l)}(w^Tx^{(l)}+w_0)\\geq 1\\\\\n",
    "&\\frac{1}{N}\\Sigma_{l=1}^N 1-y^{(l)}(w^Tx^{(l)}+w_0)+\\frac{\\lambda}{2} ||w||^2 & otherwise\\\\\n",
    "\\end{aligned}\n",
    "\\right.$$\n",
    "其中，$\\lambda$表示为下述PENALTY。\n",
    "详细地，方法为：\n",
    "1. 随机产生初始的w值。\n",
    "2. 对于$w_1-w_N$，首先计算所有满足$y^{(l)}(w^Tx^{(l)}+w_0)\\geq 1$对应的下标集合$I$，对于每个下标，计算$\\Delta w_j=-\\frac{1}{N} \\cdot \\Sigma_{i \\in I}x_j^{(i)}\\cdot y^{(i)}+PENALTY \\cdot w_j$。对于$w_0$，$\\Delta w_0 = -\\Sigma_{i \\in I}y^{(i)}$。\n",
    "3. 更新$w_0=w_0-STEP\\_SIZE \\cdot \\Delta w_0$，$w=w-STEP\\_SIZE \\cdot \\Delta w$。\n",
    "将测试数据输入模型，得到准确度。准确度的计算方式是，模型计算出的预测值与实际值差的绝对值的平均。同时由于初始随机性的选取，我将代码运行5次，准确度与时间计算取平均值。\n",
    "## 2 参数\n",
    "经过测试与选取，我选择了如下参数：\n",
    "PENALTY = 0.001\n",
    "THRESHOLD = 1e-9\n",
    "STEP_SIZE = 0.0003\n",
    "MAX_ITERATION = 8000\n",
    "其中，选择PENALTY = 0.001是为了降低w的平方和的占比，选择THRESHOLD = 1e-9和MAX_ITERATION = 8000是为了在保证时间较短情况下增加准确度，选择STEP_SIZE = 0.0003是为了增加准确度，使得其缓慢迭代。\n",
    "## 3 结果\n",
    "根据上述参数配置，得到结果如下：\n",
    "train_test: 0.9325\n",
    "test_acc: 0.92\n",
    "Running time: 2.78125 Second\n",
    "测试可以发现，其在THRESHOLD约为$1 \\cdot 10^{-9}$时达到稳定。同时，设置为此值时，迭代次数差不多为8000（当设置为$1 \\cdot 10^{-8}$时，迭代次数约为4000）。\n",
    "测试可以发现，其基本保持不变，因此我选择最大值，即STEP_SIZE = 0.0003。\n",
    "对于PENALTY来说，由于并未规定取多少，因此我取了可以使得运行时间最短同时准确率最高的0.001。\n",
    "此时，运行时间为2.78125s，准确率为0.92。\n",
    "最终结果为：\n",
    "w=[-0.61092617,-2.29493064e-01,-1.32799101e-02,-2.37979400e-01,2.50455259e-01\n",
    "   -1.45104633e-01,9.34174521e-02,3.64139625e-02,-1.06806357e-01,-1.27525606e-01\n",
    "   -1.87934020e-01,1.07382368e-01,-2.22253625e-01,-8.32127053e-02,-2.72055261e-01\n",
    "    7.61677805e-02,-2.29022182e-02,-1.11535143e-01,3.70389924e-02,-6.91222326e-03\n",
    "    7.80859202e-03,3.87350089e-02,-2.39034455e-04,-4.33990394e-03,4.08749327e-02\n",
    "   -3.02514495e-02,1.03504090e-02,3.15397126e-02,-4.06747076e-03,-7.86600723e-04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200 th: [0.00020503] acc: 0.605 loss: [0.79000089]\n",
      "epoch: 400 th: [0.00016291] acc: 0.76 loss: [0.48000172]\n",
      "epoch: 600 th: [0.00014868] acc: 0.805 loss: [0.39000256]\n",
      "epoch: 800 th: [0.00010908] acc: 0.83 loss: [0.34000345]\n",
      "epoch: 1000 th: [0.00010175] acc: 0.845 loss: [0.31000434]\n",
      "epoch: 1200 th: [9.88169835e-05] acc: 0.835 loss: [0.33000523]\n",
      "epoch: 1400 th: [0.00010148] acc: 0.855 loss: [0.2900062]\n",
      "epoch: 1600 th: [0.00010414] acc: 0.855 loss: [0.29000723]\n",
      "epoch: 1800 th: [0.00011213] acc: 0.87 loss: [0.2600083]\n",
      "epoch: 2000 th: [0.00010143] acc: 0.875 loss: [0.25000938]\n",
      "epoch: 2200 th: [0.00010346] acc: 0.875 loss: [0.2500105]\n",
      "epoch: 2400 th: [1.03285445e-05] acc: 0.845 loss: [0.31001164]\n",
      "epoch: 2600 th: [2.72818845e-06] acc: 0.875 loss: [0.25001276]\n",
      "epoch: 2800 th: [2.11272992e-05] acc: 0.855 loss: [0.29001393]\n",
      "epoch: 3000 th: [0.00011975] acc: 0.86 loss: [0.28001512]\n",
      "epoch: 3200 th: [3.38460937e-05] acc: 0.87 loss: [0.26001629]\n",
      "epoch: 3400 th: [1.558432e-06] acc: 0.88 loss: [0.2400175]\n",
      "epoch: 3600 th: [9.11994669e-05] acc: 0.865 loss: [0.27001872]\n",
      "epoch: 3800 th: [2.08821046e-06] acc: 0.87 loss: [0.26002001]\n",
      "epoch: 4000 th: [1.32332415e-05] acc: 0.88 loss: [0.2400212]\n",
      "epoch: 4200 th: [1.31786343e-05] acc: 0.88 loss: [0.2400224]\n",
      "epoch: 4400 th: [0.00012627] acc: 0.87 loss: [0.26002359]\n",
      "epoch: 4600 th: [2.61177548e-07] acc: 0.895 loss: [0.2100246]\n",
      "epoch: 4800 th: [3.35004538e-07] acc: 0.895 loss: [0.21002556]\n",
      "epoch: 5000 th: [1.44363435e-05] acc: 0.88 loss: [0.24002651]\n",
      "epoch: 5200 th: [1.51035505e-05] acc: 0.89 loss: [0.2200277]\n",
      "epoch: 5400 th: [1.58793013e-05] acc: 0.88 loss: [0.24002883]\n",
      "epoch: 5600 th: [1.78572088e-05] acc: 0.885 loss: [0.23002994]\n",
      "epoch: 5800 th: [6.3881296e-05] acc: 0.9 loss: [0.20003102]\n",
      "epoch: 6000 th: [1.87241158e-06] acc: 0.905 loss: [0.19003211]\n",
      "epoch: 6200 th: [2.5019455e-06] acc: 0.905 loss: [0.19003299]\n",
      "epoch: 6400 th: [2.55073684e-06] acc: 0.91 loss: [0.1800338]\n",
      "epoch: 6600 th: [2.55073681e-06] acc: 0.905 loss: [0.19003462]\n",
      "epoch: 6800 th: [2.56036581e-06] acc: 0.91 loss: [0.18003543]\n",
      "epoch: 7000 th: [2.56036578e-06] acc: 0.915 loss: [0.17003622]\n",
      "epoch: 7200 th: [2.58249581e-06] acc: 0.92 loss: [0.16003701]\n",
      "epoch: 7400 th: [2.62126721e-06] acc: 0.92 loss: [0.16003779]\n",
      "epoch: 7600 th: [2.66252348e-06] acc: 0.925 loss: [0.15003855]\n",
      "epoch: 7800 th: [8.98468329e-05] acc: 0.915 loss: [0.17003941]\n",
      "epoch: 8000 th: [9.04727749e-05] acc: 0.925 loss: [0.15004043]\n",
      "train_acc: 0.9425\n",
      "test_acc: 0.925\n",
      "[-0.61001775] [[-0.22823233]\n",
      " [-0.02163924]\n",
      " [-0.23879767]\n",
      " [ 0.24932084]\n",
      " [-0.14453281]\n",
      " [ 0.09465104]\n",
      " [ 0.03689461]\n",
      " [-0.10624629]\n",
      " [-0.12877544]\n",
      " [-0.19005849]\n",
      " [ 0.10904288]\n",
      " [-0.22159298]\n",
      " [-0.08060215]\n",
      " [-0.27498502]\n",
      " [ 0.07394298]\n",
      " [-0.02620278]\n",
      " [-0.1125004 ]\n",
      " [ 0.0377991 ]\n",
      " [-0.00694991]\n",
      " [ 0.0165741 ]\n",
      " [ 0.0380815 ]\n",
      " [ 0.00255858]\n",
      " [-0.00800293]\n",
      " [ 0.04665018]\n",
      " [-0.03489932]\n",
      " [ 0.01391827]\n",
      " [ 0.02840818]\n",
      " [-0.00409745]\n",
      " [-0.00208082]]\n",
      "Running time: 3.65625 Second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "PATH_X_TRAIN = \"./data/X_train.csv\"\n",
    "PATH_Y_TRAIN = \"./data/Y_train.csv\"\n",
    "PATH_X_TEST = \"./data/X_test.csv\"\n",
    "PATH_Y_TEST = \"./data/Y_test.csv\"\n",
    "IS_CONTAINHEAD = True\n",
    "IS_NORMALIZE = False\n",
    "NEED_RESHAPE = True\n",
    "PENALTY = 0.0001\n",
    "THRESHOLD = 1e-9\n",
    "STEP_SIZE = 0.0003\n",
    "MAX_ITERATION = 8000\n",
    "\n",
    "# 打印选项\n",
    "# 打印每固定迭代次数结果\n",
    "PRINT_EPOCH = True\n",
    "PRINT_RATE = 200\n",
    "# 打印总结果\n",
    "PRINT_RES = True\n",
    "# 打印运行时间\n",
    "PRINT_TIME = True\n",
    "\n",
    "\n",
    "def change_dir():\n",
    "    import os\n",
    "    import sys\n",
    "    os.chdir(sys.path[0])\n",
    "    return sys.path[0]\n",
    "\n",
    "\n",
    "def read_csv(path, option=\"x\", need_reshape=NEED_RESHAPE):\n",
    "    data = np.loadtxt(path, dtype=float, delimiter=',',\n",
    "                      skiprows=int(IS_CONTAINHEAD))\n",
    "    if option == \"y\":\n",
    "        data[data == 0] = -1\n",
    "        if need_reshape:\n",
    "            data = np.reshape(data, (np.shape(data)[0], 1))\n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize_data(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i, :] = (data[i, :] - mean) / std\n",
    "    return data\n",
    "\n",
    "\n",
    "def caculate_by_gradient_decent(train_x, train_y, test_x, test_y, penalty=PENALTY, threshold=THRESHOLD, step_size=STEP_SIZE, max_iteration=MAX_ITERATION, is_normalize=IS_NORMALIZE):\n",
    "    if (is_normalize):\n",
    "        train_x = normalize_data(train_x)\n",
    "        test_x = normalize_data(test_x)\n",
    "    data_num = np.shape(train_x)[0]\n",
    "    feature_dim = np.shape(train_x)[1]\n",
    "    w = np.random.rand(feature_dim, 1)*0.01\n",
    "    w_0 = np.random.rand(1)*0.01\n",
    "\n",
    "    it = 1\n",
    "    th = 0.1\n",
    "    while it < max_iteration and th > threshold:\n",
    "        a = np.tile(w_0, [data_num, 1])+train_x@w\n",
    "        ksi = a*train_y\n",
    "        index = (ksi < 1)[:, 0]\n",
    "\n",
    "        dw = np.zeros([feature_dim, 1])\n",
    "        dw_0 = 0\n",
    "        # for w_other\n",
    "        dw = -np.transpose(train_x[index])@train_y[index]\n",
    "        dw = dw/data_num+penalty*w\n",
    "        # for w_0\n",
    "        dw_0 = -sum(train_y[index])/data_num\n",
    "\n",
    "        w_0_ = w_0-step_size*dw_0\n",
    "        w_ = w-step_size*dw\n",
    "\n",
    "        th = np.sum(np.square(w_ - w)) + np.square(w_0_ - w_0)\n",
    "        it = it + 1\n",
    "\n",
    "        w = w_\n",
    "        w_0 = w_0_\n",
    "\n",
    "        if PRINT_EPOCH and it % PRINT_RATE == 0:\n",
    "            predict_y = caculate_predict_y(w_0, w, test_x)\n",
    "            print(\"epoch:\", it, \"th:\", th, \"acc:\", caculate_acc(\n",
    "                test_y, predict_y), \"loss:\", caculate_loss(test_y, predict_y, w_0, w))\n",
    "    return w_0, w\n",
    "\n",
    "\n",
    "def caculate_predict_y(w_0, w, data_x):\n",
    "    predict_y = np.tile(\n",
    "        w_0, [np.shape(data_x)[0], 1])+data_x@w\n",
    "    predict_y = [[1] if i > 0 else [-1] for i in predict_y]\n",
    "    return predict_y\n",
    "\n",
    "\n",
    "def caculate_acc(test_y, predict_y):\n",
    "    correct_prediction = np.equal(predict_y, test_y)\n",
    "    accuracy = np.mean(correct_prediction.astype(np.float64))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def caculate_loss(test_y, predict_y, w_0, w, penalty=PENALTY):\n",
    "    ksi = 1-test_y*predict_y\n",
    "    index = (ksi < 0)[:, 0]\n",
    "    ksi[index] = 0\n",
    "    loss = penalty/2*(w_0*w_0+sum(w*w))+sum(ksi)/np.shape(test_y)[0]\n",
    "    return loss\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_x_train = read_csv(PATH_X_TRAIN, \"x\")\n",
    "    data_y_train = read_csv(PATH_Y_TRAIN, \"y\")\n",
    "    data_x_test = read_csv(PATH_X_TEST, \"x\")\n",
    "    data_y_test = read_csv(PATH_Y_TEST, \"y\")\n",
    "    # print(\"read done!\")\n",
    "    res_w_0, res_w = caculate_by_gradient_decent(data_x_train,\n",
    "                                                 data_y_train, data_x_test, data_y_test)\n",
    "    if PRINT_RES:\n",
    "        print(\"train_acc:\", caculate_acc(data_y_train,\n",
    "                                         caculate_predict_y(res_w_0, res_w, data_x_train)))\n",
    "        print(\"test_acc:\", caculate_acc(data_y_test,\n",
    "                                        caculate_predict_y(res_w_0, res_w, data_x_test)))\n",
    "        print(res_w_0, res_w)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.process_time()\n",
    "    change_dir()\n",
    "    main()\n",
    "    end_time = time.process_time()\n",
    "    if PRINT_TIME:\n",
    "        print(\"Running time: %s Second\" % (end_time-start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b53b142aa665138b047fc8d4e709385ba7a8975f30daa0cd1a1e70c7b20d025"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
